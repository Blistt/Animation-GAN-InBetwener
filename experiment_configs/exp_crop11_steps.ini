[DEFAULT]
device = cuda:1

#-------------------------------------- Loss function parameters --------------------------------------'''
adv_l = nn.BCEWithLogitsLoss().to(device)
r1 = EDT_Loss(device=device, sub_loss='laplacian').to(device)
r2 = nn.BCELoss().to(device)
r3 = GDL(device)
adv_lambda = 0.2
r1_lambda = 1.0       
r2_lambda = 2.0
r3_lambda = 1.0


#-------------------------------------- Training loop parameters --------------------------------------'''
n_epochs = 4
input_dim = 2
label_dim = 1
hidden_channels = 64
batch_size = 8
lr = 0.0002
b1 = 0.9
b2 = 0.999
img_size = (512, 512)
target_size = (373, 373)
gen_extra = 0   
disc_extra = 0
training_mode = steps
overfit_batch = False 



#-------------------------------------- Model --------------------------------------'''
gen = UNetCrop(input_dim, label_dim).to(device)
gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(b1, b2))
disc = DiscriminatorCrop(label_dim, hidden_channels).to(device)
disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(b1, b2))
save_checkpoints = False


#-------------------------------------- Dataset parameters --------------------------------------'''
binary_threshold = 0.75
train_data_dir = /data/farriaga/atd_12k/Line_Art/train_10k/
test_data_dir = /data/farriaga/atd_12k/Line_Art/test_2k_original/
test_data_dir = mini_datasets/mini_real_test_triplets/

#-------------------------------------- Visualization parameters --------------------------------------'''
display_step = 10
plot_step = 1

#-------------------------------------- Model Loading parameters --------------------------------------'''
pretrain = none